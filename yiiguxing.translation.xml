<application>
  <component name="AppStorage">
    <histories>
      <item value="This works great in principle. But in practice, like many algorithms centered on atomic updates to a single location, it scales horribly when there are more than a few participants using the same Exchanger. So the implementation instead uses a form of elimination arena, that spreads out this contention by arranging that some threads typically use different slots, while still ensuring that eventually, any two parties will be able to exchange items. That is, we cannot completely partition across threads, but instead give threads arena indices that will on average grow under contention and shrink under lack of contention. We approach this by defining the Nodes that we need anyway as ThreadLocals, and include in them per-thread index and related bookkeeping state. (We can safely reuse per-thread nodes rather than creating them fresh each time because slots alternate between pointing to a node vs null, so cannot encounter ABA problems. However, we do need some care in resetting them between uses.) Implementing an effective arena requires allocating a bunch of space, so we only do so upon detecting contention (except on uniprocessors, where they wouldn't help, so aren't used). Otherwise, exchanges use the single-slot slotExchange method. On contention, not only must the slots be in different locations, but the locations must not encounter memory contention due to being on the same cache line (or more generally, the same coherence unit). Because, as of this writing, there is no way to determine cacheline size, we define a value that is enough for common platforms. Additionally, extra care elsewhere is taken to avoid other falseunintended sharing and to enhance locality, including adding padding (via @Contended) to Nodes, embedding &quot;bound&quot; as an Exchanger field. The arena starts out with only one used slot. We expand the effective arena size by tracking collisions; i.e., failed CASes while trying to exchange. By nature of the above algorithm, the only kinds of collision that reliably indicate contention are when two attempted releases collide -- one of two attempted offers can legitimately fail to CAS without indicating contention by more than one other thread. (Note: it is possible but not worthwhile to more precisely detect contention by reading slot values after CAS failures.) When a thread has collided at each slot within the current arena bound, it tries to expand the arena size by one. We track collisions within bounds by using a version (sequence) number on the &quot;bound&quot; field, and conservatively reset collision counts when a participant notices that bound has been updated (in either direction). The effective arena size is reduced (when there is more than one slot) by giving up on waiting after a while and trying to decrement the arena size on expiration. The value of &quot;a while&quot; is an empirical matter. We implement by piggybacking on the use of spin-&gt;yield-&gt;block that is essential for reasonable waiting performance anyway -- in a busy exchanger, offers are usually almost immediately released, in which case context switching on multiprocessors is extremely slowwasteful. Arena waits just omit the blocking part, and instead cancel. The spin count is empirically chosen to be a value that avoids blocking 99% of the time under maximum sustained exchange rates on a range of test machines. Spins and yields entail some limited randomness (using a cheap xorshift) to avoid regular patterns that can induce unproductive growshrink cycles. (Using a pseudorandom also helps regularize spin cycle duration by making branches unpredictable.) Also, during an offer, a waiter can &quot;know&quot; that it will be released when its slot has changed, but cannot yet proceed until match is set. In the mean time it cannot cancel the offer, so instead spinsyields. Note: It is possible to avoid this secondary check by changing the linearization point to be a CAS of the match field (as done in one case in the Scott &amp; Scherer DISC paper), which also increases asynchrony a bit, at the expense of poorer collision detection and inability to always reuse per-thread nodes. So the current scheme is typically a better tradeoff. On collisions, indices traverse the arena cyclically in reverse order, restarting at the maximum index (which will tend to be sparsest) when bounds change. (On expirations, indices instead are halved until reaching 0.) It is possible (and has been tried) to use randomized, prime-value-stepped, or double-hash style traversal instead of simple cyclic traversal to reduce bunching. But empirically, whatever benefits these may have don't overcome their added overhead: We are managing operations that occur very quickly unless there is sustained contention, so simplerfaster control policies work better than more accurate but slower ones. Because we use expiration for arena size control, we cannot throw TimeoutExceptions in the timed version of the public exchange method until the arena size has shrunken to zero (or the arena isn't enabled). This may delay response to timeout but is still within spec. Essentially all of the implementation is in methods slotExchange and arenaExchange. These have similar overall structure, but differ in too many details to combine. The slotExchange method uses the single Exchanger field &quot;slot&quot; rather than arena array elements. However, it still needs minimal collision detection to trigger arena construction. (The messiest part is making sure interrupt status and InterruptedExceptions come out right during transitions when both methods may be called. This is done by using null return as a sentinel to recheck interrupt status.) As is too common in this sort of code, methods are monolithic because most of the logic relies on reads of fields that are maintained as local variables so can't be nicely factored -- mainly, here, bulky spin-&gt;yield-&gt;blockcancel code. Note that field Node.item is not declared as volatile even though it is read by releasing threads, because they only do so after CAS operations that must precede access, and all uses by the owning thread are otherwise acceptably ordered by other operations. (Because the actual points of atomicity are slot CASes, it would also be legal for the write to Node.match in a release to be weaker than a full volatile write. However, this is not done because it could allow further postponement of the write, delaying progress.)" />
      <item value="Region Grid" />
      <item value="Dummy Grid" />
      <item value="Purchase Cost Tax" />
      <item value="total Price Contain Tax" />
      <item value="actual Gross Profit Amount" />
    </histories>
    <option name="languageScores">
      <map>
        <entry key="CHINESE" value="5" />
        <entry key="ENGLISH" value="6" />
      </map>
    </option>
  </component>
  <component name="Cache">
    <option name="lastTrimTime" value="1636806440513" />
  </component>
  <component name="Translation.Cache">
    <option name="lastTrimTime" value="1674891673258" />
  </component>
  <component name="Translation.Settings">
    <option name="primaryLanguage" value="CHINESE" />
    <option name="targetLanguageSelection" value="LAST" />
  </component>
  <component name="Translation.States">
    <option name="newTranslationDialogWidth" value="598" />
    <option name="newTranslationDialogX" value="2207" />
    <option name="newTranslationDialogY" value="450" />
    <histories>
      <item value="ユニットの画像ファイル名" />
      <item value="CY2018以降のE-BIKE (DU-E7000以前)" />
      <item value="CY2018以前のE_BIKE (DU-E8000以降. ※E8000だからE7000より新しいように思えるが、実際には古い)" />
      <item value="DU-E 8000以降" />
      <item value="Genres" />
      <item value="システム仕様書(別紙)-ユニット一覧参照" />
      <item value="エラーチェックの種類" />
      <item value="ドライブユニット" />
      <item value="TODO: DUUnitを継承するように修正する" />
      <item value="接続可能なスプリンタースイッチ名" />
      <item value="対応していないマスターが接続されている" />
      <item value="マスターユニット" />
      <item value="モバイル版未対応" />
      <item value="モデル名" />
      <item value="ユニット名" />
      <item value="ファイル名" />
      <item value="アプリでの表示名" />
      <item value="Manufacture ID" />
      <item value="DUに接続されているバッテリーの名称を取得" />
      <item value="画面に表示する場合は" />
      <item value="他社バッテリの製品名" />
      <item value="他社バッテリ（通信でメーカが判別できるもの)" />
      <item value="時刻をカスタマイズ可能か" />
      <item value="can Customize Time" />
      <item value="バッテリー" />
      <item value="&quot;ユニッタのカタログ番号&quot;はありません" />
      <item value="カテゴリ" />
      <item value="deserialize" />
      <item value="識別子がSwitchか" />
      <item value="Function Border" />
      <item value="復旧時にFWファイル名特定不可" />
      <item value="PL作業画面など" />
      <item value="Lightスイッチ選択時" />
      <item value="Switch Button Having" />
      <item value="ジャンクションA" />
      <item value="ワイヤレスユニット" />
      <item value="ジャンクション" />
      <item value="DCASとn RF無線(UPDATENRF)のFWを持つユニット" />
      <item value="is Dfly Setting Supported" />
      <item value="ユニットの並び順を機能別に定義" />
      <item value="EW ジャンクション" />
      <item value="クラスファイルの作成" />
      <item value="DB上でその他に分類されるカテゴリ(CJ,不明、その他、FWが壊れたユニット" />
      <item value="CANアダプター" />
      <item value="Series Noが不明なユニットを認識した場合にこのクラスで表現します。" />
      <item value="enum entry CJ Enum constant ordinal: 19 盒式连接器" />
      <item value="カセットジャンクション" />
      <item value="E-BIKEにはEWWのユニットは接続されないがEW-EN 100をEWWと定義しているためEWWを含める" />
      <item value="make Sorted Unit Category" />
      <item value="sorted Unit Categories" />
    </histories>
    <option name="languageScores">
      <map>
        <entry key="CHINESE" value="254" />
        <entry key="DANISH" value="1" />
        <entry key="ENGLISH" value="67" />
        <entry key="JAPANESE" value="255" />
      </map>
    </option>
  </component>
</application>